import cv2
from ultralytics import YOLO
import os

# --- 1. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Path ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥  ---
# ‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))

# ‡∏ä‡∏µ‡πâ‡πÄ‡∏õ‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà Model (‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Git ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
MODEL_PATH = os.path.join(CURRENT_DIR, 'models', 'best.pt')

# ‡∏ä‡∏µ‡πâ‡πÄ‡∏õ‡πâ‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà Video (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
# ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ fish_video.mp4, fish_video_2.mp4 ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏™‡∏±‡∏Å‡∏≠‡∏±‡∏ô‡∏Ñ‡∏£‡∏±‡∏ö
VIDEO_PATH = os.path.join(CURRENT_DIR, 'fish_video.mp4') 

# ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
OUTPUT_DIR = os.path.join(CURRENT_DIR, 'runs', 'detect', 'video_result')


def has_display():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ GUI (‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‚Äî ‡∏ñ‡πâ‡∏≤‡∏£‡∏±‡∏ô‡πÉ‡∏ô Docker ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ"""
    display = os.environ.get('DISPLAY', '')
    if not display:
        return False
    try:
        cv2.namedWindow("__test__", cv2.WINDOW_NORMAL)
        cv2.destroyWindow("__test__")
        return True
    except Exception:
        return False


def main():
    print(f"üìÇ ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: {CURRENT_DIR}")

    # --- ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå ---
    if not os.path.exists(MODEL_PATH):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: {MODEL_PATH}")
        print("üí° ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° git pull ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡πÑ‡∏ü‡∏•‡πå best.pt ‡πÉ‡∏™‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå models ‡∏ô‡∏∞‡∏Ñ‡∏£‡∏±‡∏ö")
        return

    if not os.path.exists(VIDEO_PATH):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà: {VIDEO_PATH}")
        print("üí° ‡∏•‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏≠‡∏µ‡∏Å‡∏ó‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÑ‡∏´‡∏°")
        return

    # --- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• ---
    print(f"üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {os.path.basename(MODEL_PATH)}")
    try:
        model = YOLO(MODEL_PATH)
    except Exception as e:
        print(f"‚ùå ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ: {e}")
        return

    # --- ‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ---
    print(f"üé• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠: {os.path.basename(VIDEO_PATH)}")
    cap = cv2.VideoCapture(VIDEO_PATH)

    if not cap.isOpened():
        print("‚ùå ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        return

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÑ‡∏´‡∏°
    use_gui = has_display()

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° VideoWriter (‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏°‡∏≠)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, 'output.mp4')
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

    if use_gui:
        # ‡∏°‡∏µ GUI ‚Äî ‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢
        cv2.namedWindow("Tilapia Detection", cv2.WINDOW_NORMAL)
        cv2.resizeWindow("Tilapia Detection", 800, 600)
        print("üü¢ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (GUI mode)... ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å")
    else:
        # ‡πÑ‡∏°‡πà‡∏°‡∏µ GUI (Docker) ‚Äî ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        print(f"üü¢ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Headless mode)... ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏ó‡∏µ‡πà {output_path}")

    frame_count = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            print("üé¨ ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
            break

        frame_count += 1

        # ‡πÉ‡∏´‡πâ AI ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö
        results = model.predict(frame, conf=0.25, verbose=False)

        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏•‡∏á‡∏ö‡∏ô‡∏†‡∏≤‡∏û
        annotated_frame = results[0].plot()

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå
        writer.write(annotated_frame)

        if use_gui:
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
            cv2.imshow("Tilapia Detection", annotated_frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        else:
            # ‡πÅ‡∏™‡∏î‡∏á progress ‡∏ó‡∏∏‡∏Å 50 frames
            if frame_count % 50 == 0:
                progress = (frame_count / total_frames * 100) if total_frames > 0 else 0
                print(f"   ‚è≥ Processing: {frame_count}/{total_frames} frames ({progress:.1f}%)")

    cap.release()
    writer.release()
    if use_gui:
        cv2.destroyAllWindows()

    print(f"‚úÖ ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô ‚Äî ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• {frame_count} frames")
    print(f"üìÅ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {output_path}")

if __name__ == "__main__":
    main()